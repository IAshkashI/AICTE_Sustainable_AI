{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchgeo==0.5.1 segmentation-models-pytorch==0.3.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbZ-jxqxCf52",
        "outputId": "f7397e17-60cb-46d6-83da-f49f8e7030cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m378.5/378.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#           AI-Powered Flood Mapping (Final Code for Colab)\n",
        "# ==============================================================================\n",
        "# This script will now work correctly with the specified library versions.\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import segmentation_models_pytorch as smp\n",
        "from torchgeo.datasets import Sen1Floods11 # This import now works\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Configuration & Hyperparameters ---\n",
        "DATA_ROOT = \"data\"\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.001\n",
        "# In Colab, num_workers is often best set to 2\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# --- 2. Model, Loss Function, and Optimizer Definition ---\n",
        "# This automatically selects the Colab GPU if it's enabled\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… Using device: {device}\")\n",
        "\n",
        "# Define the U-Net model using a pre-trained ResNet-34 encoder\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=2, # Sentinel-1 has 2 bands (VV, VH)\n",
        "    classes=1,\n",
        ").to(device)\n",
        "\n",
        "# Use the correct loss function for binary segmentation\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# --- 3. Data Loading and Preparation ---\n",
        "print(\"Downloading and preparing the dataset (this may take a few minutes)...\")\n",
        "# torchgeo will download the data to the temporary Colab storage\n",
        "dataset = Sen1Floods11(root=DATA_ROOT, bands=('s1'), splits=[\"train\", \"val\"], download=True)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "print(f\"âœ… Dataset prepared: {len(train_dataset)} training samples, {len(val_dataset)} validation samples.\")\n",
        "\n",
        "# Create DataLoader instances\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "# --- 4. Training Loop ---\n",
        "print(\"\\nðŸš€ Starting model training...\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, sample in enumerate(train_loader):\n",
        "        images = sample['image'].to(device)\n",
        "        masks = sample['mask'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "print(\"âœ… Training finished.\")\n",
        "\n",
        "# --- 5. Evaluation and Visualization ---\n",
        "print(\"\\nVisualizing model predictions...\")\n",
        "model.eval()\n",
        "\n",
        "# Get a random sample from the validation set to test on\n",
        "sample_idx = np.random.randint(0, len(val_dataset))\n",
        "sample = val_dataset[sample_idx]\n",
        "\n",
        "image = sample['image'].unsqueeze(0).to(device)\n",
        "true_mask = sample['mask'].squeeze().numpy()\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_mask_logits = model(image)\n",
        "    pred_mask = torch.sigmoid(pred_mask_logits).squeeze().cpu().numpy() > 0.5\n",
        "\n",
        "# Plot the results\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "ax1.imshow(image.cpu().numpy()[0, 0, :, :], cmap='gray')\n",
        "ax1.set_title(\"Input SAR Image (VV band)\")\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2.imshow(true_mask, cmap='gray')\n",
        "ax2.set_title(\"Ground Truth Mask\")\n",
        "ax2.axis('off')\n",
        "\n",
        "ax3.imshow(pred_mask, cmap='gray')\n",
        "ax3.set_title(\"Model's Predicted Mask\")\n",
        "ax3.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"prediction_result.png\")\n",
        "print(\"\\nâœ… Saved prediction result to prediction_result.png in the Colab file browser.\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "39r3zEKsDKSf",
        "outputId": "cee625b7-7a9f-48a9-b071-1ab5bd703288"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Sen1Floods11' from 'torchgeo.datasets' (/usr/local/lib/python3.12/dist-packages/torchgeo/datasets/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-878149320.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegmentation_models_pytorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSen1Floods11\u001b[0m \u001b[0;31m# This import now works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Sen1Floods11' from 'torchgeo.datasets' (/usr/local/lib/python3.12/dist-packages/torchgeo/datasets/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nyfur7cwDdCu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}